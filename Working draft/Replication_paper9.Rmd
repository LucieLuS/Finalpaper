---
title: "First Draft of Final Paper"
author: "Lucie Lu"
date: "March 19, 2018"
output: pdf_document
---


Since the 1980s, economic liberalization has advanced remarkably. There has been a marked shift in the orientation of the trade and industrial policies for developing countries. Many developing countries moved away from a heavy reliance on direct intervention and inward-looking trade regimes toward less controlled and more export-oriented trade regimes. Simply put, they chose to liberalize their trade regimes. Many developing countries have decided to integrate their economies into a global economy by dismantling their protectionist trade policies. Countries such as Argentina, Brazil, Indonesia, Mexico have conducted substantial trade reforms respectively, including reducing tariff rates, reforming import licensing procedures in the 1980s. What drove such a substantial change in their trade policy? 



What has driven the trend in trade liberalization? For the developing countries, it is costly for them to abandon the protectionist, import-substituting industrialization strategy given that they have been the orthodoxy among developing country policymakers in the post-war period. A temporary protection for the infant industry is sometimes necessary for infant industries to gain competitiveness in trade in the developing countries. However, over time, many infant industries refuse to mature but become inefficient, and what is worse, they hold vested interests of the oligarchies. In this case, interest groups and political leaders usually benefit from the status quo of the protectionist policies. Change in the protectionist status quo is unexpected. This make the question puzzling. If the political leaders benefit from the status quo, why do they conduct reforms? Why would they choose to lower the trade barriers?


#Argument


Rodrick (1994) argues that it is very difficult for politicians to conduct liberalization reforms in normal times, but times of crises can provide an opportunity moment for undertaking structural reforms. What are the 'times of crises' to drive the structural change? Some scholars claim the economic crises may force countries to give up the protectionist old policies and move toward a market-friendly and open one. Crises may underscore the problems of the old protectionist view of a country, so countries conduct reform and liberalize to recover from the crises (Krugers, 1997). Others claim that external pressure such as a country's accession to the international institutions helps facilitate the transition. External pressures such as the World Trade Organization (WTO), IMF or trade treaties, matter (Vreeland, 2007). When developing countries join these international institutions or sign the binding international trade agreements with other developed countries, the newly joined members will show their commitment to the international regimes (Baccini & Urpelainen, 2014). A voluntary tariff reduction in a developing country will send a promising signal to the international community. 


Now, what about political reforms?  Another closely related structural change, the trend of democratization, was happening a decade before the trend to free trade. In 1975, there were around thirty democracies in the world, while by 1992, there were about eight-nine. Are these two trends causally related or happened to coincide by chance? When countries are more democratized, are they more likely to initiate trade liberalizing economic reforms? Are sharp changes in the economic reform the product of political transformation? As Rodrik argued, "Not all political transformations result in trade reform, but sharp changes in trade policy are typically the result of such transformation (1994, p. 69)." This article largely focuses on the regime type. To show that the regime type places a role in the move to free trade, I will also control for the factors of economic crisis and external pressure illustrated above.  



What remains unclear is whether political reforms affect trade policy reforms, or whether trade reforms induce political transition. The research design of observational data plus classic regression model cannot fully address this endogeneity issue. The fundamental problem of drawing causal inference in an observational data is to make the right comparison. To compare apples to apples, we need to hold other things equal. Because in observational studies, treatments are observed rather than assigned, so it is not possible to consider the observed data under different treatment are randomly assigned. It is highly possible that the two groups of countries (one with democratization, the other without) are fundamentally different in many ways. All of the potential confounders (whether observed or unobserved) will obscure the causal relationship we try to infer. Milner and Kubota's article (2005), "Why the Move to Free Trade? Democracy and Trade Policy in Developing Countries" is a classic piece. They provide a systematic investigation on the relationship between regime change and trade liberalization. They have suggested that democracy has led to trade liberalization. I will cast doubt on their analysis strategy that has relied on controlling for confounding covariates through linear regression. I suggest that a more sophisticated research design, matching can to some extent solve the selection bias problem in the observational data.  


I am going to replicate and extend the paper on Milner and Kubota's argument: When countries become more democratic, they are more willing to open their markets to the international economy. I have a couple of concerns on their original work. They present the average treatment effect of democracy on average tariff level in the Ordinary Least Squares (OLS) model, which at best only presents the two variables are positively correlated. Given the limitation of observational data, it is not convincing to draw a causal relationship between the two. To extend their original piece, inspired by Angrist and Pischke (2015), I will conduct a regression with matching approach to overcome the possible selection problem in the observational data. The goal of this replication paper is to present a regression-based causal story: countries that have democratized will tend to lower their levels of trade barriers.  


The paper will be divided into three main sections. The first section will briefly describe the variables, measures, the reasons for adjustment. The second section is an empirical analysis of a classic OLS approach with a discussion of statistical inference. It will move on to employ a combination of matching and regression to make a good comparison between country with and without political reform demonstrate the treatment effect of democratization.  



```{r include=FALSE, cache=FALSE}
## To make the pdf file do
## render("exploration4.Rmd",output_format=pdf_document())

require(knitr)
opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="small",    # slightly smaller font for code
  echo=TRUE,
  results='markup',
  strip.white=TRUE,
  fig.path='figs/fig',
  cache=FALSE,
  highlight=TRUE,
  width.cutoff=132,
  size='footnotesize',
  out.width='.9\\textwidth',
  message=FALSE,
  comment=NA)
```


```{r initialize,echo=FALSE, message=FALSE, warning=FALSE}
##First, just setup the R environment for today:
if(!file.exists('figs')) dir.create('figs')

options(SweaveHooks=list(fig=function(){
			   par(mar=c(3.5, 3, 1.1, 0),
			       pty="s",
			       mgp=c(1.5,0.5,0),
			       oma=c(0,0,0,0))},
			 echo=function(){options(continue=" ") ##Don't show "+" prompts,
			 options(prompt=" ")
			 }),
	digits=4,
	scipen=8,
	width=132
	)
options(error=function(){options(prompt="> ",continue="+ ");NULL})

#To prepare the environment
library(readstata13)
library(dplyr)
library(ggplot2)
library(stargazer)

#install.packages("devtools")
library(devtools)

library(foreign)
#install.packages("gplots")
library(gplots)

library(lmtest)
library(sandwich)

```


#Section I: Data on Trade Liberalization and Democratization

The data that I use in the following analysis is a data set compiled by Milner and Kubota (2005). It is a time-series cross-sectional (TSCS) data, covering 179 developing countries from 1980 to 1999. It include various measures not only on trade policy but also of a series of political regime measures, economic development measures and so on. The central hypothesis is that an increase in democracy will lead to a reduction in trade barriers, ceteris paribus.    


The data Milner and Kubota have collected on the developing countries demonstrate a significant change in the measure of trade policy. *Tariff*, a country's unweighted average statutory tariff rate collected, is a key measure of a country's trade policy in year *t*. The historical trend shows that a dramatic decline in the average tariff level across countries has happened from 1982 to 1999. Statutory tariff rate has decreased by over sixty percent, from an average about 30 percent in 1980 to around 12 percent in 1999 in the developing countries.

```{r, eval=T, echo=F, results="hide"}
library(readstata13)
mydata <- read.dta13(file.choose())
#View(mydata)
#Subset the large dataset
mydata2 <- mydata[,c(2,3,14,7,15,5,40,17,4,8,10,16), drop=F]

#View(mydata2)
colnames(mydata2) <- c("Country","Year","Tariff","Openness","Regime","Democracy","Dictator","Years of Office","GATT/WTO","Economic Crisis","GDP PC 95","IMF")
mydata_2 <- subset(mydata2, Year > 1979) #Select the years aftr 1979.

#The change of the statutory tariff rate
m1980 <- mean(mydata2$Tariff[mydata2$Year==1980], na.rm = T)
m1999 <- mean(mydata2$Tariff[mydata2$Year==1999], na.rm = T)
mperc<- (m1999-m1980)/m1980
mperc #-0.58

result_m_tariff <- data.frame(matrix(nrow=20, ncol=2))
colnames(result_m_tariff) <- c ("Year", "Tariff")
for (i in 1:20){
  result_m_tariff[i,1] <- i+1979
  mean <- mean(mydata2$Tariff[mydata_2$Year== i+1979], na.rm = T)
  result_m_tariff[i,2] <- mean
}
result_m_tariff
#plot(result_m_tariff)

```

More evidence of trade liberalization comes from a second measure of trade policy: the dichotomous categorization of countries into open and closed trade regimes. The data covers ninety developing countries from 1980 to 1999. In 1980, only 14 countries were scored as openness, while in 1999, 62 countries were open economies. The number of a country classified as open economy has increased by three times.

```{r, eval=T, echo=F, results="hide"}
o1980 <- sum(mydata2$Openness[mydata2$Year==1980 & mydata2$Openness == 1], na.rm = T) #14
o1999 <- sum(mydata2$Openness[mydata2$Year==1999 & mydata2$Openness == 1], na.rm = T) #62
operc <- (o1999-o1980)/o1980

```

Evidence of democratization among the developing countries is also plentiful. To measure regime type, the paper uses the 21-Point Polity Score, ranging from -10 for a highly autocratic state to 10 for a highly democratic state. The average Polity IV score for about 110 developing countries that fell from around -3.4 to -4.7 and increased sharply to a score of 1.8 in 1999. It suggests that although many regimes on averages with mixes of democratic and autocratic features (-5 to 5), the wave of democratization has been evident since the mid-1970s. Similarly, the dichotomous regime shows how the number of democracies has increased over time. The series show that the process of democratization has started in the 1970s. In 1970, less than 20 developing countries were quantified as democracies. Over three decades, there has been a four-fold increase in the number of democracies among the developing countries.

```{r, eval=T, echo=F, results="hide"}

result_m_regime_2 <- data.frame(matrix(nrow=30, ncol=2))
colnames(result_m_regime_2) <- c ("Year", "PolityScore")
for (i in 1:30){
  result_m_regime_2[i,1] <- i+1969
  mean <- mean(mydata2$Regime[mydata2$Year== i+1969], na.rm = T)
  result_m_regime_2[i,2] <- mean
}
result_m_regime_2

#plot(result_m_regime_2)

```

```{r, eval=T, echo=F, results="hide"}

result_m_regime_3 <- data.frame(matrix(nrow=30, ncol=2))
colnames(result_m_regime_3) <- c("Year", "Democracy")

for (i in 1:30){
  result_m_regime_3[i,1] <- i+1969
  counter <- sum (mydata2$Democracy[mydata2$Year== i+1969 & mydata2$Democracy ==1], na.rm=T)
  result_m_regime_3[i,2] <- counter
}

result_m_regime_3

#plot(result_m_regime_3)
```



##Data and Measures


**Independent Variables**  
*Tariff* is a country's average statutory tariff rate between 1980 and 1999. However, this is poorly measured with a large number of missing data in the data set. To be fair, it is notoriously difficult to measure and hard to find time-series and cross-sectional data on this measure.  

*Openness*, is our second measure of trade liberalization with dichotomous classification of trade regimes into closed (=0) and open (=1) ones. This measure includes a broader domain than the average tariff rate: non-tariff trade barriers, average tariff rate, black market exchange rate, and general economic structure of a country. According to Kornai (1992), a country is coded as closed if any of the following is true: nontariff barriers cover 40 percent or more of trade; average tariff rates are 40 percent or more; the black market exchange rate depreciated by 20 percent or more relative to the official exchange rate during the 1970s or 1980s, and there was a state monopoly on exports. This measure of trade policy can be used for robustness check. 


**Dependent Variable**

*Regime (Polity Score)* is a 21-poinit scale that measures variations both within democracies and among autocracies. This measurement comes from Polity III and Polity IV. It ranges from -10 (highly autocratic) to 10 (highly democratic). 

*Dictator* is a measure of the variations of autocracies differentiated by single-party regime, military regime and personalist regimes. It is coded as 1-8 with various characteristics of a regime type.  


**Control Variables**  

*GDP per capita* is A lagged value of per capita real GDP based in 2005. The economic development is likely to affect its trade policy and its political regime change. More developed countries tend to be more economically and politically liberal.    


*Economic Crisis* is an extreme event that occurs in that specific year rather than an economic variable with yearly change. To code that year with economic crisis, one of the two conditions hold: either the country's inflation rate is 40 percent or more and it increases by 25 percent or more from the year before, or per capita GDP falls by 15 percent or more from the previous year (=1). When countries experience crisis, the political leaders tend to conduct political and economic reforms to address the crisis. They are more likely to liberalize their trade regime because of a domestic demand or a conditionality of foreign aid.  

*GATT/WTO Member* is A lagged variable indicating whether a country is in the GATT/WTO(=1) or not. Joining a WTO induce member countries to lower their trade barriers. Also, WTO members tend to welcome new members intending to adopt liberal policies in both economic and political domains.  

*Years of Office* counts the number of years a government has been in office. It ranges from 0 to 44, with the mean of 8.4. It is included in the control variable because the number of years a government in power will have an impact on both political and economic reforms. A new government might indicate a change in leadership and new idea.



The summary of statistics follows in Table 1.


```{r, eval = TRUE, echo = FALSE, results = "hide", message = FALSE, warning = FALSE}
#summary(mydata_2)
#str(mydata_2)
#dim(mydata_2)

#########Explore the data
#Check the missing values
#table(mydata_2$Tariff, useNA="ifany") #The missing values: NA = 2683
sum(mydata_2$Tariff == "  ", na.rm=T) #if there is any missing valus in the blank
sum(mydata_2$Tariff == "0", na.rm=T) #20
is.na(mydata_2)[1,] #From this, we can see only the variable "Tariff" has missing values

#Check the missing values of Tariff before 1980 
mydata2_3<- subset(mydata2, Year <= 1979)
#table(mydata2_3$Tariff, useNA="ifany") #The missing values: NA = 2683

#desribe the data
library(psych)
#subset the data without country name
mydata_2_des_noc <- mydata_2[,!names(mydata_2)%in%c("Country")]
#basic descriptive Statistics
data2_des <- describe(mydata_2_des_noc, na.rm=T, check=T, skew=F, quant=c(.25,.5,.75))
data2_des

```

```{r Table data description, results='asis', echo = FALSE, message=FALSE}
#install.packages("stargazer") If you haven't already installed. Install stargazer.
library(stargazer)
#Now use stargazer to format the linear model
stargazer(mydata_2_des_noc, header = FALSE, iqr=T,
          title = "Summary Statistics", digits = 1, out = "table1.txt",
          no.space = TRUE, font.size = "footnotesize")
```


#Section II: Empirical analysis: The OLS Model


Our central dependent variable is a country' trade policy in year *t*. We want to explain the changes of the extent of openness of the trade regime of the country on average. We use two ways of measuring trade policy. The first measure is a country's unweighted average statutory tariff rate (*TARIFF*). A decline of tariff rates indicates a more liberalized trade policy of a country. The mean of the statutory tariff rate is 21% between 1980 to 1999. However, it is poorly measured. This measurement may not be valid or reliable to capture the latent variables of the trade policy concept that I am interested in. In the periods of 1980s and 1990s, I still have 2683 missing values (14% of the total). I may end up drawing inaccurate inference due to the measurement problem.


```{r Checking missing values, results='asis', echo = FALSE, message=FALSE, include=F}

#table(mydata_2$Tariff, useNA="ifany") #The missing values from 1980 t0 1999: NA = 2683
sum(mydata_2$Tariff == "  ", na.rm=T) #if there is any missing valus in the blank
sum(mydata_2$Tariff, na.rm=T)
2683/18628

is.na(mydata_2)[1,] #From this, we can see only the variable "Tariff" has missing values

##---

mydata2_3<- subset(mydata2, Year <= 1979)
table(mydata2_3$Tariff, useNA="ifany") #The missing values: NA = 1780

table(mydata2$Openness, useNA="ifany") #The missing values of openness: NA = 2580
```

My central independent variable is the type of political regime in place in a country in year *t*. As noted, the Polity Score ranging from -10 to 10 captures the institutional differences between democracies and autocracies regarding the fairness and openness of political competition and the size of the electorate. The mean of *Regime (Polity Score)* is -1.1, which indicates on average over this period a majority of these developing countries have mixes of democratic and autocratic features. It is later converted as a dichotomous variable *Democracy* with countries scoring below 6 in the Polity Score as autocracies (=0) and those above 6 as democracies (=1).        

The correlation coefficient itself is simply a way to describe how the two variables vary together. Here, I first look at the bivariate relationship between the average tariff rate and polity score. The correlation coefficient *r* is -0.12. From Table 2, we can see there are negative relationships between the dependent variable, the independent variable and the control variables (except WTO members). It is noted that the covariate coefficients between the dependent variable, independent variable and cofounders are low. This correlation matrix provide evidence of a low possibility of the multicollinearity issue in the later regression analysis.


```{r bivariate relationship1, out.width = '85%', eval = TRUE, echo = FALSE, results = "hide", message = FALSE, warning = FALSE}

plot (mydata2$Regime, mydata2$Tariff, col = "darkblue", pch = 20, xlab = "Regime Type (Polity Score)", ylab = "Tariff Rate (in percentage)",
      main = "Bivariate Relationship bewtween \n Regime Type and Tariff Rate")

OLS_1 <- lm(Tariff ~ Regime, data=mydata2)
abline(OLS_1)

r_tr <- cor(mydata2$Tariff, mydata2$Regime, use = "pairwise.complete.obs")

rr <- mydata2$Regime[!is.na(mydata2$Regime)]
rt <- mydata2$Tariff[!is.na(mydata2$Tariff)]

text(quantile(rr, .95), quantile(rt, .99), paste("r=",round(r_tr,2)), font=2)
```

```{r bivariate relationship2, eval = TRUE, echo = FALSE, results = "hide", message = FALSE}
Regime <- mydata2$Regime
Tariff <- mydata2$Tariff
lnGDP <- log(mydata2[,"GDP PC 95"])
EC <- mydata2[,"Economic Crisis"]
WTO <- mydata2[,"GATT/WTO"]
YO <- mydata2[,"Years of Office"]

matrix_cor <- data.frame(Tariff, Regime, lnGDP, EC, WTO, YO)
#as.matrix(matrix_cor)
```

```{r bivariate relationship3, eval = TRUE, echo = FALSE, results = "hide", message = FALSE}
rcor<-cor(matrix_cor,use="pairwise.complete.obs")
for(i in 1:6){
  for(j in 1:6){
    if(j<i){rcor[i,j] <- NA}
}}
round(rcor,2)
```

```{r bivariate relationship4, eval = TRUE, echo = FALSE, results='hide', message = FALSE, warning = FALSE, include=FALSE}

#install.packages("xtable",repos = "http://cran.us.r-project.org")
library(xtable)
names <- c("Tariff rate", "Regime (Polity Score)", "GDP per capita (log)", "Economic Crisis", "GATT/WTO Member", "Years of Office") 
rownames(rcor) <- names
TAB1<-round(rcor,2)
xtable(TAB1)
```

```{r bivariate relationship5, results = "asis", message = FALSE, warning = FALSE}
print(xtable::xtable(rcor, caption = "Correlation Matirx: Correlations among Variables and Confounders"),type = "latex",
      html.table.attributes="border=1")
```


Following Achen (2005)'s Rule of Three, I have laid out the reasons to control for the three covariates: GDP per capita, economic crisis and WTO membership. The fourth one, "year of office"" is added for additional check. Only covariates that meet the condition of affecting both the treatment and outcome variables confound the observed relationship between the two (Rubin, 1997; Achen, 1982). I hope that through control of these relevant covariates, the treatment effect of democratization is less cofounded. I lag all of the independent variables by one year to some extent account for the endogeneity issue. The basic OLS equation estimating the relationship between democracy and trade policy is:  

$tradepolicy_{i,t} = \beta_0 + \beta_1*REGIME_{i,t-1} + \beta_2*GDPPC_{i,t-1} + \beta_3*ECCRISIS_{i,t-1} + \beta_4*WTO_{i,t-1} + \beta_5*OFFICE_{i,t-1} + \varepsilon_i$  


Table 3 shows that on average more democratic regimes tend to have lower tariff rates. In almost all of the regressions, regime type is correctly signed, as expected. In equation (5), an expected 0.13 unit decrease in tariff rate (in percentage) for every one unit increase in democracy in Polity Score. Tariff rates expect to drop from about its mean at 20.8 percent to about 20.67 percent when the regime polity score increases by point 1. Moving from an absolute autocracy (-10) to a perfect democracy (10) induces 2.6 percent decline in tariffs.  

```{r myregression OLS1, results='asis', echo = FALSE, results = "hide", message=FALSE, warning=FALSE}
mydata3 <- mydata[,c(2,3,14,7,31,11,41,28,49,13,21,34), drop=F]
colnames(mydata3) <- c("Country","Year","Tariff","Openness","Regime(t-1)","Democracy(t-1)","Dictator(t-1)","Years of Office(t-1)",
                       "GATT/WTO(t-1)","Economic Crisis(t-1)","GDP PC 95(t-1)","IMF(t-1)")

Regime_l1 <- mydata3[,"Regime(t-1)"]
WTO_l1 <- mydata3[,"GATT/WTO(t-1)"]
YO_l1 <- mydata3[,"Years of Office(t-1)"]
EC_l1 <- mydata3[,"Economic Crisis(t-1)"]
IMF_l1 <- mydata3[,"IMF(t-1)"]
GDP_l1 <- mydata3[,"GDP PC 95(t-1)"]
lnGDP_l1 <- log(mydata3[,"GDP PC 95(t-1)"])

OLS_3_0 <- lm(Tariff ~ Regime_l1, data=mydata3)
summary(OLS_3_0)$coefficient

OLS_3_1 <- lm(Tariff ~ Regime_l1 + log(GDP_l1), data=mydata3)
#OLS_3_1_2 <- lm(Tariff ~ Regime_l1 + lnGDP_l1, data=mydata3)
#summary(OLS_3_1)

OLS_3_2 <- lm(Tariff ~ Regime_l1 + log(GDP_l1) + EC_l1, data=mydata3)
#summary(OLS_3_2)

OLS_3_3 <- lm(Tariff ~ Regime_l1 + log(GDP_l1) + WTO_l1, data=mydata3)
#summary(OLS_3_3) #the closest

#OLS_3_4_0 <- lm(Tariff ~ Regime_l1 + GDP_l1 + WTO_l1 + IMF_l1, data=mydata3)
#summary(OLS_3_4)

OLS_3_4 <- lm(Tariff ~ Regime_l1 + log(GDP_l1) + YO_l1, data=mydata3)
#summary(OLS_3_4)

OLS_3_5_0 <- lm(Tariff ~ Regime_l1 + log(GDP_l1) + EC_l1 + WTO_l1, data=mydata3)
coef(OLS_3_5_0)

#OLS_3_5_2 <- lm(Tariff ~ Regime_l1 + log(GDP_l1) + EC_l1 + WTO_l1 + YO_l1, data=mydata3)
#summary(OLS_3_5_2)

```


```{r myregression OLS1 Table, results='asis', echo = FALSE, message = FALSE, warning=FALSE}

library(stargazer)
stargazer(OLS_3_1, OLS_3_2, OLS_3_3, OLS_3_4, OLS_3_5_0, header = FALSE, df = FALSE,
          title = "Multiple Linear Regression Model: Results",
          covariate.labels = c("Regime (Polity Score)", "GDP per capita", "Economic Crisis", "GATT/WTO Member", "Years of Office"),
          dep.var.caption = "Table 2: Tariff Rates and Polity Scores",
          dep.var.labels = "Tariff Rates", 
          column.sep.width = "0.3pt", no.space = TRUE, font.size = "footnotesize")
```

Panel data may have problems that violate the standard assumptions necessary for ordinary least squares, so I will do statistical inference about an unobserved population by correcting for the standard errors with bootstrap method and panel-corrected robust standard errors in the next section. Before that, I will briefly discuss the advantages and potential problems of using the OLS.  


What assumptions do we have about the unmeasured forces influencing the outcome variables? In the linear regression, we assume linearity as a function form of the measured regressors and the dependent variable. However, all it requires is the independent variables should not be *perfectly* collinear (Achen, 1982). I have checked this assumption in the various residual plots (figures are not shown). We also assume the unmeasured error terms are random. In a linear regression model, the dependent variable is a function of the observed independent variables and some unobserved factors represented by the disturbance term (Achen, 1982). These unobserved factors in the disturbance term need to be random. A different drawing from the disturbance may produce different values of dependent variable and hence different coefficients. This assumption will be revisited in a moment. According to Achen (1982), if these assumptions are met, the coefficient estimates from the OLS are consistent, meaning they will be very near to their true value in a large sample almost all the time. In other words, in general conditions, regression will produce fairly accurate estimates if we set up the model correctly. Great resilience is a strength of ordinary linear regression (Achen, 1982). That is probably why we should analyze our data with this powerful tool at the first place.


```{r residual diagnostic plots 1 on non-linearity assumption, eval=T, echo=F, results="hide", include=F, message=F} 

#Residual plot

OLS_3_0 <- lm(Tariff ~ Regime, data=mydata2, na.action = na.exclude)
OLS_3_res <- resid (OLS_3_0)
plot(mydata2$Regime, OLS_3_res, ylab = "Residuals", xlab = "Regime", main = "Residual plots: Tariff")
abline(0,0)

#plot(OLS_3_0)

# Evaluate Nonlinearity
# component + residual plot
library(car)

crPlots(OLS_3_0)

OLS_3_5 <- lm(Tariff ~ Regime_l1 + GDP_l1 + EC_l1 + WTO_l1 + YO_l1, data=mydata3, na.action = na.exclude)

crPlots(OLS_3_5)
# Ceres plots 
#ceresPlots(OLS_3_5)
##Comment: the variable GDP_l1 apparently is an issue, which needs to be transformed. Fix and check in the following "OLS_3_5_2."

OLS_3_5_0 <- lm(Tariff ~ Regime_l1 + log(GDP_l1) + EC_l1 + WTO_l1, data=mydata3, na.action = na.exclude)

crPlots(OLS_3_5_0)
# Ceres plots 
#ceresPlots(OLS_3_5_2)

##Comment: The linearity assumption seems okay, except the economic crisis one. I will go back and fix it.

```


```{r residual diagnostic plots2, results='hide', echo = FALSE, message = FALSE, warning=FALSE, include=F}

##plot the multiple variables (attempt to remove x2)

OLS_3_1 <- lm(Tariff ~ Regime_l1 + GDP_l1, data=mydata3, na.action = na.exclude)
OLS_3_1yres <- resid(OLS_3_1)
OLS_3_1x1x2res <- resid(lm(Regime_l1 ~ GDP_l1,data=mydata3, na.action = na.exclude))
OLS_3_1yx2res <- resid(lm(Tariff ~ GDP_l1,data=mydata3, na.action = na.exclude))

#plot(resid(lm(x1 ~ x2)), resid(lm(y ~ x2)), frame = FALSE, col = "black", bg = "lightblue", pch = 21, cex = 2)
#abline(lm(I(resid(lm(x1 ~ x2))) ~ I(resid(lm(y ~ x2)))), lwd = 2)

plot(OLS_3_1x1x2res, OLS_3_1yx2res, frame = FALSE, col = "black", bg = "lightblue", pch = 21, cex = 2)
abline(lm(I(OLS_3_1x1x2res) ~ I(OLS_3_1yx2res)), lwd = 2)

##Comments: There are residual variabilities left after removing x2 (GDP_l1).
```

I am also concerned about the partial relationship between tariff rate and democracy score. I am interested in seeing what percent of the variation in the full multiple regression model (Model 4 in Table 3) cannot be explained by the independent variable but can be explained by the rest of the confounders.

```{r model evaluation work on it later, results='hide', echo = FALSE, message = FALSE, warning=FALSE, include=F}

#We may be interested in seeing what percent of the variation in the response cannot be explained by the predictors in the reduced model (i.e., the model OLS_3_1 specified by H0), but can be explained by the rest of the predictors in the full model (OLS_3_5_0).

OLS_3_1 <- lm(Tariff ~ Regime_l1 + log(GDP_l1), data=mydata3,  na.action = na.exclude)
OLS_3_5_0 <- lm(Tariff ~ Regime_l1 + log(GDP_l1) + EC_l1 + WTO_l1, data=mydata3, na.action = na.exclude)

#anova(OLS_3_1, OLS_3_5_0)
#warning: the sizes of the dataset are not the same. Need to fix it.
```

```{r summary of coefficients in binary variables, results='hide', echo = FALSE, message = FALSE, warning=FALSE, include=F}
mydata4 <- mutate(mydata3, Regime_l1_Bi = 1*(Regime_l1 >= 6))


OLS_3_0B <- lm(Tariff ~ Regime_l1_Bi, data=mydata4)
summary(OLS_3_0B)$coefficient

OLS_3_1B <- lm(Tariff ~ Regime_l1_Bi + log(GDP_l1), data=mydata4)
summary(OLS_3_1B)$coefficient

OLS_3_2B <- lm(Tariff ~ Regime_l1_Bi + log(GDP_l1) + EC_l1, data=mydata4)
summary(OLS_3_2B)$coefficient

OLS_3_3B <- lm(Tariff ~ Regime_l1_Bi + log(GDP_l1) + WTO_l1, data=mydata4)
summary(OLS_3_3B)$coefficient #the closest

#OLS_3_4_0 <- lm(Tariff ~ Regime_l1 + GDP_l1 + WTO_l1 + IMF_l1, data=mydata3)
#summary(OLS_3_4)

OLS_3_4B <- lm(Tariff ~ Regime_l1_Bi + log(GDP_l1) + YO_l1, data=mydata4)
summary(OLS_3_4B)$coefficient


OLS_3_5B <- lm(Tariff ~ Regime_l1_Bi + log(GDP_l1) + EC_l1 + WTO_l1, data=mydata4, na.action = na.exclude)
summary(OLS_3_5B)$coefficient

#The coefficient estimate summarizes the difference in average tariff rates between the democratic countries and non-democratic countries. Democratic countries will have 0.3% tariff rates lower on average than non-democratice countries. 
```

```{r prepare a test small dataset, eval=T, echo=F, results="hide", warning=F} 

mydata4 <- mydata3
Regime_l1 <- mydata3[,"Regime(t-1)"]

## Recode this variable into 1= "democracy (polity score is 6 or more) or more" versus 0="non-democracy (polity score is 6 or less)'' category:
mydata4 <- mutate(mydata3, Regime_l1_Bi = 1*(Regime_l1 >= 6))
#Check the recoding
with(mydata4, table(Regime_l1_Bi, Regime_l1,useNA="ifany"))
#I turned Polity's Regime variable into a dichotomous variable with countries scoring below 6 as autocracies and those above 6 as democracies (=1).

save(mydata4,file="mydata4.rda")

row.has.na <- apply(mydata4, 1, function(x){any(is.na(x))})
sum(row.has.na)

mydata4_small <- mydata4[!row.has.na,]
summary(mydata4_small)
nrow(mydata4)#5370
nrow(mydata4_small)#662

save(mydata4_small,file="mydata4_NAremoved.rda")

```

```{r try binary variables in small dataset, results='hide', echo = FALSE, message = FALSE, warning=FALSE, include=F}

Regime_l1_Bi_s <- mydata4_small$Regime_l1_Bi
GDP_l1_s <- mydata4_small$`GDP PC 95(t-1)`
EC_l1_s <- mydata4_small$`Economic Crisis(t-1)`
WTO_l1_s <- mydata4_small$`GATT/WTO(t-1)`
YO_l1_s <- mydata4_small$`Years of Office(t-1)`

OLS_3_0Bs <- lm(Tariff ~ Regime_l1_Bi_s, data=mydata4_small)
summary(OLS_3_0Bs)$coefficient #-3.054

OLS_3_1Bs <- lm(Tariff ~ Regime_l1_Bi_s + log(GDP_l1_s), data=mydata4_small)
summary(OLS_3_1Bs)$coefficient #0.09

OLS_3_2Bs <- lm(Tariff ~ Regime_l1_Bi_s + log(GDP_l1_s) + EC_l1_s, data=mydata4_small)
summary(OLS_3_2Bs)$coefficient #0.81

OLS_3_3Bs <- lm(Tariff ~ Regime_l1_Bi_s + log(GDP_l1_s) + WTO_l1_s, data=mydata4_small)
summary(OLS_3_3Bs)$coefficient #-0.12

#OLS_3_4_0 <- lm(Tariff ~ Regime_l1 + GDP_l1 + WTO_l1 + IMF_l1, data=mydata3)
#summary(OLS_3_4)

OLS_3_4Bs <- lm(Tariff ~ Regime_l1_Bi_s + log(GDP_l1_s) + YO_l1_s, data=mydata4_small)
summary(OLS_3_4Bs)$coefficient #-1.37


OLS_3_5Bs <- lm(Tariff ~ Regime_l1_Bi_s + log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small, na.action = na.exclude)
summary(OLS_3_5Bs)$coefficient #0.58

#Here, the sign for Regime_l1_Bi_s has flipped. Simpson's Paradox problem might exist: For example, if you have a categorical and continuous predictor then the continuous predictor could easily flip sign if the categorical one is added and within each category the sign is different than for the overall score. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2266743/
```

```{r find a better modelling strategy lmrob, results='hide', echo = FALSE, message = FALSE, warning=FALSE, include=F}

require(MASS)
require(robustbase)
summary(OLS_3_5Bs)$coefficient ## lm model


lmrob_5Bs <- lmrob(Tariff ~ Regime_l1_Bi_s + log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small, control = lmrob.control(max.it = 100))
summary(lmrob_5Bs)$coefficient## lmrob model, all in correct signs

#In regression modeling, lmrob is a robust statistics, which could be considered to handle unusual observations that do not follow the general trend of the data set. 'Robust' means that the tests have good power for a wide variety of distributions.

#The lmrob output from the lmrob function provides 'Robustness weights' to give us information about the outliers in observations by evaluating their weight and summarize statistics from  the remaining observations.

#https://www.rdocumentation.org/packages/robustbase/versions/0.92-5/topics/lmrob
```

```{r a better modelling strategy lmrob can put in table, results='hide', echo = FALSE, message = FALSE, warning=FALSE, include=F}

lmrob_0Bs <- lmrob(Tariff ~ Regime_l1_Bi_s, data=mydata4_small, control = lmrob.control(max.it = 100))
summary(lmrob_0Bs)$coefficient #-4.57

lmrob_1Bs <- lm(Tariff ~ Regime_l1_Bi_s + log(GDP_l1_s), data=mydata4_small, control = lmrob.control(max.it = 100))
summary(lmrob_1Bs)$coefficient #0.09

lmrob_2Bs <- lm(Tariff ~ Regime_l1_Bi_s + log(GDP_l1_s) + EC_l1_s, data=mydata4_small, control = lmrob.control(max.it = 100))
summary(lmrob_2Bs)$coefficient #0.81

lmrob_3Bs <- lm(Tariff ~ Regime_l1_Bi_s + log(GDP_l1_s) + WTO_l1_s, data=mydata4_small, control = lmrob.control(max.it = 100))
summary(lmrob_3Bs)$coefficient #-0.11

lmrob_4Bs <- lm(Tariff ~ Regime_l1_Bi_s + log(GDP_l1_s) + YO_l1_s, data=mydata4_small, control = lmrob.control(max.it = 100))
summary(lmrob_4Bs)$coefficient #-1.37

lmrob_5Bs <- lmrob(Tariff ~ Regime_l1_Bi_s + log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small, control = lmrob.control(max.it = 100))
summary(lmrob_5Bs)$coefficient #-1.37

```

```{r myregression lmrob Table 2, results='asis', echo = FALSE, message = FALSE, warning=FALSE}

library(stargazer)
stargazer(lmrob_0Bs, lmrob_1Bs, lmrob_2Bs, lmrob_3Bs, lmrob_4Bs, lmrob_5Bs, header = FALSE, df = FALSE,
          title = "Multiple Linear Regression Model: Results",
          covariate.labels = c("Regime (Polity Score)", "GDP per capita", "Economic Crisis", "GATT/WTO Member", "Years of Office"),
          dep.var.caption = "Table 2: Tariff Rates and Polity Scores",
          dep.var.labels = "Tariff Rates", 
          column.sep.width = "0.3pt", no.space = TRUE, font.size = "footnotesize")
```

```{r check estimates unbiasedness, results='hide', echo = FALSE, message = FALSE, warning=FALSE, include=F}


#z is the experiment, shuffle the mydata4$Regime_l1_Bi variable to create a pretend experiment

set.seed(2018)
mydata4_small$Z <-sample(rep(c(0,1),nrow(mydata4_small)/2)) 

#Define a potential outcome?

#Invent TrueATE

#First come up with a way for covariates to be related to the potential outcome under control (y0). This produces background noise in the outcome (i.e. variation that has nothing to do with the treatment assignment or treatment effect.)
mydata4_small$y0 <- with(mydata4_small, 3 -  30*log(GDP_l1_s) + 26*EC_l1_s +  8*WTO_l1_s) + 
                      + 
    runif(n = nrow(mydata4_small)/2,min=min(mydata4_small$Tariff),max=max(mydata4_small$Tariff)) 
#To create background noise...no effect at all.

lm_test2 <- lm(y0 ~ log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small)
summary(lm_test2)$r.squared  #0.5962
mydata4_small$y1 <- with(mydata4_small, y0 + .8*sd(y0))
trueATE <- mean(mydata4_small$y1) - mean(mydata4_small$y0)
trueATE #36.71
.8*sd(mydata4_small$y0) #36.71

#Now, you know the trueATE: 36.71

## Observed outcome: y1 among the treated, y0 among the controls
mydata4_small$Y <- with(mydata4_small, Z*y1 + (1-Z)*y0)
lm_test3 <- lm(Y ~ log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small) #also use the covariates
summary(lm_test3)$r.squared #0.5231


## Notice that this includes all of the true covariates, just not in the correct function, plus it includes some irrelevant covariates
estATEbest_3_5Bs <- coef(OLS_3_5Bs)[["Regime_l1_Bi_s"]]

#OLS_3_5Bs <- lm(Tariff ~ Regime_l1_Bi_s + log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small, na.action = na.exclude)
estATEbest_3_5Bs #0.5762

estATEunbiased_3_5Bs <- coef(OLS_3_0Bs)[["Regime_l1_Bi_s"]]
#OLS_3_0Bs <- lm(Tariff ~ Regime_l1_Bi_s, data=mydata4_small)
estATEunbiased_3_5Bs#includes nothing (no covariates) -3.054
```

```{r check estimates unbiasedness for lmrob not figure out yet, results='hide', echo = FALSE, message = FALSE, warning=FALSE, include=F, eval=FALSE}

#Monte Carlo Simulation
#Is an estimator biased in finite samples? Is it still consistent under departures from assumptions? What is its sampling variance?

#z is the experiment, shuffle the mydata4$Regime_l1_Bi variable to create a pretend experiment

set.seed(2018)
mydata4_small$Z <-sample(rep(c(0,1),nrow(mydata4_small)/2)) 

#Define a potential outcome?

#Invent TrueATE

#First come up with a way for covariates to be related to the potential outcome under control (y0). This produces background noise in the outcome (i.e. variation that has nothing to do with the treatment assignment or treatment effect.)
mydata4_small$y0 <- with(mydata4_small, 3 -  30*log(GDP_l1_s) + 26*EC_l1_s +  8*WTO_l1_s) + 
                      + 
    runif(n = nrow(mydata4_small)/2,min=min(mydata4_small$Tariff),max=max(mydata4_small$Tariff)) 
#To create background noise...no effect at all.

lmrob_test2 <- lmrob(y0 ~ log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small)
summary(lmrob_test2)$r.squared  #0.5628

mydata4_small$y1 <- with(mydata4_small, y0 + .8*sd(y0))
trueATE <- mean(mydata4_small$y1) - mean(mydata4_small$y0)
trueATE #36.71
.8*sd(mydata4_small$y0) #36.71

#Now, you know the trueATE: 36.71

## Observed outcome: y1 among the treated, y0 among the controls
mydata4_small$Y <- with(mydata4_small, Z*y1 + (1-Z)*y0)
lmrob_test3 <- lmrob(Y ~ log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small) #also use the covariates
summary(lmrob_test3)$r.squared #0.5063

## Notice that this includes all of the true covariates, just not in the correct function, plus it includes some irrelevant covariates

estATEbest_lmrob_5Bs <- coef(lmrob_5Bs)[["Regime_l1_Bi_s"]]

#lmrob_5Bs <- lmrob(Tariff ~ Regime_l1_Bi_s + log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small, control = lmrob.control(max.it = 100))
estATEbest_lmrob_5Bs #-1.368


estATEunbiased_lmrob_0Bs <- coef(lmrob_0Bs)[["Regime_l1_Bi_s"]]
#lmrob_0Bs <- lmrob(Tariff ~ Regime_l1_Bi_s, data=mydata4_small, control = lmrob.control(max.it = 100))
estATEunbiased_lmrob_0Bs #-4.566 #includes no covariates 

```

```{r biassketch, results='hide', echo=FALSE, cache=TRUE}
set.seed(2018)

## Bias refers to a relationship between the repeated operation of a procedure and a truth.
## So we have to invent a truth (that is why we **created** potential outcomes for all units ---
## ordinarily we would not observe these quantities).

#Repeat the experiment. Each repetition reveals a different potential outcome
#for each person. Calculate the estimates from the two different estimators.
#This should show (1) bias and (2) whether one or the other is better in mean
#squared error terms. What would I do to show that one or another is consistent
#--- especially that one or the other converges to the truth more or less
#quickly as sample sizes increase?


newEstimate<-function(obsz,dat){
  newExperiment<-function(z){
    #sample(z) is permutating z
    sample(z)
  }
  #create newz
  dat$newz <- newExperiment(obsz)
  ##names(newz) <- row.names(dat)
  #create newY
  dat$newY <- with(dat,newz*y1 + (1-newz)*y0)
  #use three methods to create ATE
  theestATEbest <- coef(lm(newY~newz+log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=dat))[["newz"]]
  theestATEunbiased <- coef(lm(newY~newz,data=dat))[["newz"]]
  ## Another method of using covariates
  dat$e1 <- residuals(lm(newY~log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=dat))
  theestATEbest2 <- coef(lm(e1~newz,data=dat))[[2]]
  return(c(bestATE=theestATEbest,
           unbiasedATE=theestATEunbiased,
           bestATE2=theestATEbest2))
}

## test, maybe a good idea to test it after we create a function
## newEstimate(obsz=wrkdat$Z,dat=wrkdat)

## An unbiased estimator is one where E[estimator]=Truth. Hmmm.. Is this the right test?
set.seed(1234568)
estdists <- replicate(10000,newEstimate(obsz=mydata4_small$Z,dat=mydata4_small))

```


```{r compare trueATE and the other types of ATE,  results='hide', eval=T, echo=TRUE, cache=TRUE}

trueATE #36.71
##sampdistmeans<-apply(estdists,1,mean)
#meanATE
sampmeans <- apply(estdists[1:3,],1,mean)
#sampledistmeans: very close to the trueATE
sampmeans

#absolute difference between the estimated mean and the true ATE

bias <- abs(trueATE-apply(estdists[1:3,],1,mean)) # abs(): absoluate positive values: the differences between trueATE and the estimates
apply(estdists[1:3,],1,function(x){ mean( abs(x - trueATE) ) } )
bias
#the standard deviation of the ATE means

##Finding the standard deviation of the estimated ATEs allows us to see if our estimators are efficient.
sd <- apply(estdists[1:3,],1,sd)
sd

#the RMSE of the difference in the true ATE and the estimated ATE

##The RMSE allows us to further assess if the estimators are biased becuase it overesstimates the presence of bias. (to verify)

MSE <- apply(estdists[1:3,],1,function(x){ mean( ( x - trueATE)^2 ) })
MSE
```

```{r bivariate relationship table0, eval = TRUE, echo = FALSE, results='hide', message = FALSE, warning = FALSE, include=FALSE}

#install.packages("xtable",repos = "http://cran.us.r-project.org")
library(xtable)

sim <- as.matrix(rbind(trueATE, sampmeans, bias, sd, MSE))
#rownames(rcor) <- names
simtab<-round(sim,2)
simtab
xtable(simtab)
```

All of the three estimates are very close to the true mean I created in the simulation test. In fact, bestATE has the lowest bias out of three (its absolute distance to the true mean is the smallest one). The MSEs for bestATE and bestATE2 are relatively the same: The estimates bestATE and bestATE2 are efficient, compared to the unbiasedATE. From this simulation test, because the bestATE has the lowest bias and is the most efficient one, this estimaor is preferred. 

```{r bivariate relationship table1, results = "asis", message = FALSE, warning = FALSE}
print(xtable::xtable(sim, caption = "Simulation results from different estimates for OLS model"),type = "latex",
      html.table.attributes="border=1")
```


```{r plot the bias, RMSE and consistency, results='hide', eval=FALSE, echo=TRUE, cache=TRUE}

plot(density(estdists["bestATE",]),ylim=c(0,.25))
rug(estdists["bestATE",],col="black",line=0)
lines(density(estdists["unbiasedATE",]),col="blue")
rug(estdists["unbiasedATE",],col="blue",line=.5)
lines(density(estdists[3,]),col="orange")
abline(v=trueATE)

sampdistmeans<-apply(estdists,1,mean)
points(c(sampdistmeans[1:3],estATEunbiased_3_5Bs,estATEbest_3_5Bs), rep(0,5),
       pch=c(17,17,17,2,2),
       cex=1,col=c("black","blue","orange","green","red"))

##bestATE and bestATE2 have a little bias, but it is consistent; 
##unbiasedATE is unbiased, but it is very inefficient.

##We can reduce bias only at a potential increase in variance.

```



```{r randomization and p-value for lm, results='hide', echo = FALSE, message = FALSE, warning=FALSE, include=F}


OLS_3_5Bs <- lm(Tariff ~ Regime_l1_Bi_s + log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small, na.action = na.exclude)
simlmtest_lm5Bs <- summary(OLS_3_5Bs)$coef[2,1]
simlmtest_lm5Bs #0.5762

#Imagine we re-run the "experiment"
newExp<-function(y){
  ## A function to randomly assign treatment effect
shuffledz <- sample(mydata4_small$Z) 
newlmtest <- coef(lm(y ~ shuffledz+ log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small))[["shuffledz"]]
  return(newlmtest)
}

set.seed(19900814)
expBeta_lm5Bs <- replicate(10000, newExp(y=mydata4_small$Tariff))
mean(expBeta_lm5Bs)
plot(density(expBeta_lm5Bs)) #plot the sampling distribution under null hypothesis
rug(mean(expBeta_lm5Bs), 1, col="blue")
abline(v=simlmtest_lm5Bs,lty=2, col="red")

#One-sided p-value
pvalue_lm <- as.numeric(as.matrix(summary(expBeta_lm5Bs > simlmtest_lm5Bs)))/length(expBeta_lm5Bs)
pvalue_lm #0.2996

#Two-sided p-value
2*min(mean(expBeta_lm5Bs>=simlmtest_lm5Bs),mean(expBeta_lm5Bs<=simlmtest_lm5Bs)) #0.5992
#pretty close to the two-sided p-value obtained in the lm (0.63)
#In this case the standard assumption that the statistic follows a t distribution gives a p-value of 0.63 which is in quite good agreement with the permutation test (0.60). But we wouldn't necessarily know beforehand that they would agree.

```


```{r randomization and p-value for lmrob, results='hide', echo = FALSE, message = FALSE, warning=FALSE, include=F}

lmrob_5Bs <- lmrob(Tariff ~ Regime_l1_Bi_s + log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small, control = lmrob.control(max.it = 100))

simlmrobtest_5Bs <- summary(lmrob_5Bs)$coef[2,1]
simlmrobtest_5Bs #-1.368

#Imagine we re-run the "experiment"
newExp_lmrob<-function(y){
  ## A function to randomly assign treatment effect
shuffledz <- sample(mydata4_small$Z) 
newlmtest <- coef(lmrob(y ~ shuffledz+ log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small))[["shuffledz"]]
  return(newlmtest)
}

set.seed(19900814)
expBeta_lmrob_5Bs <- replicate(10000, newExp_lmrob(y=mydata4_small$Tariff))
mean(expBeta_lmrob_5Bs)
plot(density(expBeta_lmrob_5Bs)) #plot the null distribution
rug(mean(expBeta_lmrob_5Bs), 1, col="blue")
abline(v=simlmrobtest_5Bs,lty=2, col="red")

#One-sided p-value
pvalue_lm <- as.numeric(as.matrix(summary(expBeta_lmrob_5Bs < simlmrobtest_5Bs)))/length(expBeta_lmrob_5Bs)
pvalue_lm #0.051

#Two-sided p-value
2*min(mean(expBeta_lmrob_5Bs>=simlmrobtest_5Bs),mean(expBeta_lmrob_5Bs<=simlmrobtest_5Bs)) #0.102
#perform better than the two-sided p-value obtained in the lmrob canned function (0.19).

```


```{r error rate for lm, results='hide', echo = FALSE, message = FALSE, warning=FALSE, include=F}

#Codes to assess the false positive rate of the canned lm function

err_rate<- function(y){
    shuffledz <- sample(mydata4_small$Z) 
    ## since we know that there is no effect, then we can assess the false positive rate of lm
    sim_ps <- summary(lm(y ~ shuffledz+ log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small))$coef[2,4]
return(sim_ps)
}

set.seed(800814)
results_lm5Bs <- replicate(1000, 
err_rate(y=mydata4_small$Tariff))

mean(results_lm5Bs <= .05) #0.05. 

falsepos_lm5Bs <- as.numeric(as.matrix(summary(results_lm5Bs < .05))[3,1])/length(results_lm5Bs) #0.05
falsepos_lm5Bs

#If we run it a couple of times, the false positive rates are slightly different, but they are around 0.05. It seems to be a valid test, which actually come close to the nominal false positive rate.

#How to interpret this: you create a null effect knowing that your null hypothesis is true. Then the false positive rate 0.05, which means 5 out of 100 times, the test faslely reject the nulls (knowing the null is true but you still reject it). It fulfills its promises.

```

```{r error rate for lmrob, results='hide', echo = FALSE, message = FALSE, warning=FALSE, include=F}

#Codes to assess the false positive rate of the canned lmrob function

err_ratetlmrob<- function(y){
    require(robustbase)
    shuffledz <- sample(mydata4_small$Z) 
  sim_psrob <- summary(lmrob(y ~ shuffledz+ log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small))$coef[2,4]
return(sim_psrob)
}

set.seed(23358)
results_lmrob5Bs <- replicate(1000, err_ratetlmrob(y=mydata4_small$Tariff))

mean(results_lmrob5Bs <= .05) #0.043

falsepos_lmrob5Bs <- as.numeric(as.matrix(summary(results_lmrob5Bs < .05))[3,1])/length(results_lm5Bs) 
falsepos_lmrob5Bs #0.043

#The Type 1 error, the false positive is 0.043.
```


```{r showing valid test for lmrob, results='hide', echo = FALSE, message = FALSE, warning=FALSE, include=F}
err_ratetlmrob<- function(y){
    require(robustbase)
    shuffledz <- sample(mydata4_small$Z) 
  sim_psrob <- summary(lmrob(y ~ shuffledz+ log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small))$coef[2,4]
return(sim_psrob)
}

set.seed(23358)
nSims <- 1000
results_lmrob5Bs <- replicate(nSims, err_ratetlmrob(y=mydata4_small$Tariff))#get the p-value and store it
#Check power by summing significant p-values and dividing by number of simulations

#The frequency of p-values, or the type 1 error is 0.043. When there is no effect (in the simulation), we can see the p-value is uniformally distributed under the null. This is a valid test because we have set the type 1 error as 0.05, meaning that we can use this test to conclude we have 0.05 chance to make an error saying that there is a true effect where there is actually no true effect.


bars<-20

op <- par(mar = c(5,7,4,4)) #change white-space around graph
hist(results_lmrob5Bs, breaks=20, xlab="P-values", ylab="number of p-values\n", axes=T,
     main=paste("P-value distribution under null effect in the simulation in lmrob"),
     col="grey", xlim=c(0,1),  ylim=c(0, nSims))
axis(side=1, at=seq(0,1, 0.1))
abline(h=nSims/bars, col = "red", lty=3)



#When there is no true effect, p-values are what is called 'uniformly distributed under the null'. The p-value distribution is basically flat. Every p-value is equally likely when the null hypothesis is true, and every bar in the graph will contain 5% of all the p-values (as indicated by the dotted red line).
```


```{r effectsize and power for lm, results='hide', echo = FALSE, message = FALSE, warning=FALSE, include=F}

## doParallel will not work on all machines. 
library(foreach)
library(doParallel)
cl <- makeCluster(2) ## 2 cores on my machine
registerDoParallel(cl)

set.seed(800814)

power_fn<- function(outcome,effect){
    shuffledz <- sample(mydata4_small$Z) 
    ## since we know that there is no effect, then we can assess the false positive rate of lm
    newoutcome <- outcome - shuffledz*effect
    sim_p<- summary(lm(newoutcome ~ shuffledz+ log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small))$coef[2,4]
return(sim_p)
}

#effectsize <- seq(0.1,5, by=0.3)
#results_sim_p <- replicate(1000, power_fn(outcome=mydata4_small$Tariff, effect=0.5))

#somepower <- mean(results_sim_p <= .05) #power
#somepower

######

effectsize <- seq(0.1,5, by=0.3)
somepower <- sapply(seq(0.1,5, by=0.3), function(effectSize){
                     results_sim_p <- replicate (1000, power_fn(outcome=mydata4_small$Tariff, effect=effectSize))
                    
                     power <- (mean(results_sim_p <= .05))
                      return(power)
                  })

rbind(effectsize, somepower)

 
```


```{r effectsize and power for lmrob, results='hide', echo = FALSE, message = FALSE, warning=FALSE, include=F}

## doParallel will not work on all machines. 
library(foreach)
library(doParallel)
cl <- makeCluster(2) ## 2 cores on my machine
registerDoParallel(cl)

set.seed(800814)

power_fn_lmrob<- function(outcome,effect){
    shuffledz <- sample(mydata4_small$Z) 
    ## since we know that there is no effect, then we can assess the false positive rate of lm
    newoutcome <- outcome - shuffledz*effect
    sim_p<- summary(lmrob(newoutcome ~ shuffledz+ log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small))$coef[2,4]
return(sim_p)
}

#effectsize <- seq(0.1,5, by=0.3)
#results_sim_p <- replicate(1000, power_fn(outcome=mydata4_small$Tariff, effect=0.5))

#somepower <- mean(results_sim_p <= .05) #power
#somepower

######

effectsize <- seq(0.1,5, by=0.3)
somepower_lmrob <- sapply(seq(0.1,5, by=0.3), function(effectSize){
                     results_sim_p <- replicate (1000, power_fn_lmrob(outcome=mydata4_small$Tariff, effect=effectSize))
                    
                     power <- (mean(results_sim_p <= .05))
                      return(power)
                  })

somepower_lmrob

```

```{r, print out power and effectsize, results='hide', echo = FALSE, message = FALSE, warning=FALSE, include=F}

#tablepowers <- rbind(effectsize, somepower, somepower_lmrob)

#install.packages("xtable",repos = "http://cran.us.r-project.org")
library(xtable)

tablepowers <- as.matrix(rbind(effectsize, somepower, somepower_lmrob))
xtable(tablepowers)

print(xtable::xtable(tablepowers, caption = "Simulation results of Power and Effect Size for lm and lmrob model"),type = "latex",
      html.table.attributes="border=1")
```

```{r, plot power and effectsize, results='hide', echo = FALSE, message = FALSE, warning=FALSE, include=F}

powersdata <- data.frame(effectsize, somepower, somepower_lmrob)

stacked <- with(powersdata,
                data.frame(
                  power = c(somepower, somepower_lmrob),
                  variable = factor(rep(c("powerlm", "powerlmrob"),
                    each = NROW(powersdata))),
                      effectsize = rep(effectsize, 2)))

ggplot(data=stacked, aes(x=effectsize, y=power, colour=variable))+
geom_line()+
geom_hline(yintercept=0.8, linetype="dashed", color="black")+
  labs(title="Power and Effect Size in Simulations", x="Effect Size", y = "Power") +
  theme_classic()

```
*Power analysis of two models*:

Simulations can be uesed to estimate the statistical power of a model. The statistical power is the probability of observing a statistically significant result, if there is a true effect. When there is an effect, I hope that my statistical test is able to detect it. This denotes to high power in my study.   

Cohen describes effect size as "the degree to which the null hypothesis is false." In this simulation test, I generate different hypothetical effect sizes (from 0.1 to 5), and I calculate the number of p-values that are are lower than 0.05 ("reject the null") when I know there is a true effect (the null is false). When the effect size increases, the powers in both functions also increase. 

In a given sample size, the lmrob model has larger statistical power given an effect size. To achieve 80% statistical power, the lmrob model requires an effect size of 2, whereas the lm model requires an effect size of 3.

```{r confidence interval for lm, results='hide', echo = FALSE, message = FALSE, warning=FALSE, include=F}

#'A confidence interval is a collection of not-rejected hypotheses.'
#Under lm:
#OLS_3_5Bs <- lm(Tariff ~ Regime_l1_Bi_s + log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small, na.action = na.exclude)

#Under lm assumption:
confint(OLS_3_5Bs, parm="Regime_l1_Bi_s")
cicanned_lm <- round(confint(OLS_3_5Bs, parm="Regime_l1_Bi_s"),2)


#############
mytest2ForUniRoot_test<-function(x,y=mydata4_small$Tariff,z=mydata4_small$Regime_l1_Bi){
			 newy<-y-(z*x)
			 .05-summary(lm(newy~ z + log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small))$coef["z","Pr(>|t|)"]
}

#mytest2ForUniRoot_test(20)
#mytest2ForUniRoot(-20)
upperlim<-uniroot(mytest2ForUniRoot_test,interval=c(0,20),extendInt="no")
lowerlim<-uniroot(mytest2ForUniRoot_test,interval=c(-20,0),extendInt="no")
ciroot_lm <- round(c(lowerlim$root,upperlim$root),2)


#This is another way to find the confidence interval using uniroot. The function here is still about each new H0 as shown before. The difference is  ".05-summary(lm(newy~z+s))$coef["z","Pr(>|t|)"]".0.05 is the significance level, this line of code will generate positive results if the p value of certain hypothesis is less than 5%, leading to the rejection of that hypothesis.


### The root means the solution that makes a function equal to 0, and uniroot command is telling R to find only one solution. Second, the upperlim and lowerlim represent the two-tail test. Both upperlim and lowerlim tell R to search only one root from the interval 0 to 20 or -20 to 0. 
###"extendInt=No" is telling R not extend search if a different sign cannot be found. In other words, returning to "error" if R cannot find the root with different sign.

cicanned_lm 
ciroot_lm
```


```{r confidence interval for lmrob, results='hide', echo = FALSE, message = FALSE, warning=FALSE, include=F}

#'A confidence interval is a collection of not-rejected hypotheses.'
#Under lmrob:
lmrob_5Bs <- lmrob(Tariff ~ Regime_l1_Bi_s + log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small, control = lmrob.control(max.it = 100))

confint(lmrob_5Bs, parm="Regime_l1_Bi_s")

cicanned_lmrob <- round (confint(lmrob_5Bs, parm="Regime_l1_Bi_s"), 2)

##############

mytest3ForUniRoot_test<-function(x,y=mydata4_small$Tariff,z=mydata4_small$Regime_l1_Bi){
			 newy<-y-(z*x)
			 .05-summary(lmrob(newy~ z + log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small))$coef["z","Pr(>|t|)"]
}

#mytest3ForUniRoot_test(20)
#mytest3ForUniRoot(-20)
upperlim<-uniroot(mytest3ForUniRoot_test,interval=c(0,20),extendInt="no")
lowerlim<-uniroot(mytest3ForUniRoot_test,interval=c(-20,0),extendInt="no")
ciroot_lmrob <- round(c(lowerlim$root,upperlim$root),2)

cicanned_lmrob
ciroot_lmrob
```

```{r Confidence Interval lm using pvalue, results='hide', echo = FALSE, message = FALSE, warning=FALSE, include=F}

## Confidence interval: choose alpha=.05
set.seed(2349854)

#OLS_3_5Bs <- lm(Tariff ~ Regime_l1_Bi_s + log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small, na.action = na.exclude)
#simlmtest_lm5Bs <- summary(OLS_3_5Bs)$coef[2,1]
#simlmtest_lm5Bs #0.5762


#Imagine we re-run the "experiment"
newExp_lm<-function(y){
  ## A function to randomly assign treatment effect
shuffledz <- sample(mydata4_small$Z) 
newlmtest <- coef(lm(y ~ shuffledz+ log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small))[["shuffledz"]]
  return(newlmtest)
}

myTestStat4_lm<-function(x,newz=shuffledz,y=mydata4_small$Tariff){
  shuffledz <- sample(mydata4_small$Z) 
  newy<-y-(newz*x)
	coef(lm(newy~ newz + log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small))[["newz"]]
}

MyFisherTest4_lm <- function(x,thez){
  ## return a p-value
  randDistH0<-replicate(1000,myTestStat4_lm(x=x))
  pTwoSided <- 2*min(c(mean(randDistH0>=simlmtest_lm5Bs),
		      mean(randDistH0<=simlmtest_lm5Bs)))
  return(pTwoSided)
}
#######
######
library(foreach)
res1<-foreach(h=seq(-5,5,0.5),.combine='c') %dopar% {message("."); MyFisherTest4_lm(x=h, thez=mydata4_small$Regime_l1_Bi)}
#Now I can use foreach to execute the function repeatedly, passing it the values -10 through 5, and returning the results in a list, called x


printCIres1lm <- rbind(seq(-5,5,0.5),res1)
printCIres1lm

#CI for lm by using using permutation here is [-2.5, 1.5].
```

```{r Confidence Interval lmrob using pvalue, results='hide', echo = FALSE, message = FALSE, warning=FALSE, include=F}

lmrob_5Bs <- lmrob(Tariff ~ Regime_l1_Bi_s + log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small, control = lmrob.control(max.it = 100))

simlmrobtest_5Bs <- summary(lmrob_5Bs)$coef[2,1]
simlmrobtest_5Bs

## Confidence interval: choose alpha=.05
set.seed(2349854)
#Imagine we re-run the "experiment"
newExp_lmrob<-function(y){
  ## A function to randomly assign treatment effect
shuffledz <- sample(mydata4_small$Z) 
newlmtest <- coef(lmrob(y ~ shuffledz+ log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small))[["shuffledz"]]
  return(newlmtest)
}

myTestStat4<-function(x,newz=shuffledz,y=mydata4_small$Tariff){
  shuffledz <- sample(mydata4_small$Z) 
  newy<-y-(newz*x)
	coef(lmrob(newy~ newz + log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small))[["newz"]]
}

MyFisherTest4 <- function(x,thez){
  ## return a p-value
  randDistH0<-replicate(1000,myTestStat4(x=x))
  pTwoSided <- 2*min(c(mean(randDistH0>=simlmrobtest_5Bs),
		      mean(randDistH0<=simlmrobtest_5Bs)))
  return(pTwoSided)
}
#######
######
#library(foreach)
res1_lmrob<-foreach(h=seq(-5,5,0.5),.combine='c') %dopar% {message("."); MyFisherTest4(x=h, thez=mydata4_small$Regime_l1_Bi)}
#Now I can use foreach to execute the function repeatedly, passing it the values -10 through 5, and returning the results in a list, called x


printCIres1lmrob <- rbind(seq(-5,5,0.5),res1_lmrob)
printCIres1lmrob

#CI here is [0,3].
```

```{r create Xtable to collect p-values and confidence interval}


ci_permute <- round(as.matrix(rbind(printCIres1lm, res1_lmrob)),2)
ci_permute

xtable(ci_permute)

print(xtable::xtable(ci_permute, caption = "Searching for non-rejected intervals under permuation for lm and lmrob models"),type = "latex",
      html.table.attributes="border=1")

ci_permute_lm <- c(-2.5, 1.5)
ci_permute_lmrob <- c(0, 3)
```

```{r create Xtable to collect p-values and confidence interval 2}
#######
collect_ci <- as.matrix(rbind(cicanned_lm, ciroot_lm, cicanned_lmrob,ciroot_lmrob))
collect_ci

collect_ci_test <- as.matrix(rbind(collect_ci, ci_permute_lm, ci_permute_lmrob))

collect_ci_test

#install.packages("xtable",repos = "http://cran.us.r-project.org")
library(xtable)

xtable(collect_ci_test)

print(xtable::xtable(collect_ci_test, caption = "Collections of Confudence Intervals under pumutation for lm and lmrob models"),type = "latex",
      html.table.attributes="border=1")

```


```{r, eval=F}

set.seed(2349854)
myFisherTest4Uniroot<-function(x,thez){
  ## return a p-value
  randDistH0<-replicate(1000,MyFisherTest4(x=x))
  #thez <- mydata4_small$Regime_l1_Bi
  pTwoSided <- 2*min(c(mean(randDistH0>=simlmrobtest_5Bs),
		      mean(randDistH0<=simlmrobtest_5Bs)))
  return(.05-pTwoSided)
}

upperlimF<-uniroot(myFisherTest4Uniroot,interval=c(0,4),extendInt="no")
upperlimF

lowerlimF<-uniroot(myFisherTest4Uniroot,interval=c(-4,0),extendInt="no")
lowerlimF

CIUniroot <- round(c(lowerlimF$root, upperlimF$root), digits=2)
CIUniroot
#Here the Confidence interval is [-0.1773, 2.94].
```



```{r bootstrapping confidence interval}

OLS_3_5Bs <- lm(Tariff ~ Regime_l1_Bi_s + log(GDP_l1_s) + EC_l1_s + WTO_l1_s, data=mydata4_small, na.action = na.exclude)
#662
summary(OLS_3_5Bs)
coef(OLS_3_5Bs)[2] #0.5762

set.seed (20892380)

beta.obs.boot <- numeric (10000)

#origin.fit <- fitted(origin)
#origin.resid <- resid(origin)
for (i in 1: 10000){
  this.ind <- sample (662, 662, replace = TRUE)
  beta.obs.boot[i] <- coef(lm(mydata4_small$Tariff[this.ind] ~ mydata4_small$Regime_l1_Bi[this.ind] + log(GDP_l1_s)[this.ind] + EC_l1_s[this.ind] + WTO_l1_s[this.ind]))[2]
}

plot(density(beta.obs.boot), lwd=3, col = "steelblue")
#v=as.numeric(coef(OLS_3_5Bs)[2])
abline(v=as.numeric(coef(OLS_3_5Bs)[2]), lwd=3, col= "gold")

#bootstrap percentil interval
quantile(beta.obs.boot,c(.025,.975))
CI_lm_m1 <- round(quantile(beta.obs.boot,c(.025,.975)), 2)
CI_lm_m1
#[-1.90, 3.11]


 
```

```{r bootstrapping confidence interval for lm}
set.seed (20892380)

par(mfrow=c(2,2))

#bootstrap 4 times
for (i in 1:4){

nsamps<-10000
resample_original<-data.frame(t
                              (replicate(nsamps,
      coef(lm(Tariff ~ Regime_l1_Bi_s + log(GDP_l1_s) + EC_l1_s + WTO_l1_s,
              data=sample_n(mydata4_small[,c("Regime_l1_Bi","Tariff")],size=662,replace=TRUE))))))

  plot(density(resample_original$Regime_l1_Bi_s), main = "Distribution of the test statistic using bootstrap approach")

}

#bootstrap percentile interval
quantile(resample_original[,"Regime_l1_Bi_s"],c(.025,.975))

CI_lm_m2 <- round(quantile(resample_original[,"Regime_l1_Bi_s"],c(.025,.975)),2)

CI_lm_m2
#[-2.53, 2.48]

```



```{r coverage rate}

```


```{r bootstrap hypothesis test}
theta.hat <- summary(OLS_3_5Bs)$coef[2,1]

#null: H0: theta.hat=0

set.seed(19900814)

n <- nrow (mydata4_small)
nboot <- 10000
theta.star <- double(nboot)

#Draw a bootstrap sample of the total observations with replacement
for(i in 1:nboot){
  k <- sample(1:n, replace = T)
  theta.star[i] <- summary(lm((Tariff[k] ~ Regime_l1_Bi[k] + log(GDP_l1_s)[k] + EC_l1_s[k] + WTO_l1_s[k]), data=mydata4_small))$coef[2,1]
}

#theta.star is a vector of the observed values of the test statistic calculated for bootstrap samples.

# lower-tailed test of theta = 0
ltpv <- mean(theta.star <= 0)
ltpv
#0.9902

mean (theta.hat < theta.star)


# upper-tailed test of theta = 0
utpv <- 1 - ltpv
utpv
#0.0098
#one-sided p-value

#The lower-tailed P-value is the ?? such that the ??-th quantile of the distribution of the bootstrap samples theta.star is equal to the hypothesized value of the parameter under the null hypothesis (here zero).

## upper-tailed test of theta = 0
2 * min(ltpv, 1 - ltpv) 
#0.02 is the two-sided p-value
```


set.seed (20892380)

beta.obs.boot <- numeric (10000)

#origin.fit <- fitted(origin)
#origin.resid <- resid(origin)
for (i in 1: 10000){
  this.ind <- sample (662, 662, replace = TRUE)
  beta.obs.boot[i] <- coef(lm(mydata4_small$Tariff[this.ind] ~ mydata4_small$Regime_l1_Bi[this.ind] + log(GDP_l1_s)[this.ind] + EC_l1_s[this.ind] + WTO_l1_s[this.ind]))[2]
}

plot(density(beta.obs.boot), lwd=3, col = "steelblue")
#v=as.numeric(coef(OLS_3_5Bs)[2])
abline(v=as.numeric(coef(OLS_3_5Bs)[2]), lwd=3, col= "gold")

#bootstrap percentil interval
quantile(beta.obs.boot,c(.025,.975))
CI_lm_m1 <- round(quantile(beta.obs.boot,c(.025,.975)), 2)
CI_lm_m1
#[-1.90, 3.11]





##Statistical Inference 

The term "observational study" refers to a situation in which a specific intervention was offered nonrandomly to a population or in which a population was exposed nonrandomly to a well-defined treatment (Gelman & Hill, 2007, p. 186). The target of statistical inference in this study is the observational data -- the population itself. I am interested in the developing countries in the 1980s and 1990s. Some of them have democratized politically, while some have not. What I am trying to present is a hypothetical experiment. The treatment effect of the democratization is that political reforms lead to economic reforms for developing countries in that period. We do not have a sample in this situation. What we want to show is the effect of a treatment in this time period. I do statistical inference because what is worrisome is that there may be no relationship between these two factors for any unit at all (Fisher's null hypothesis). I will use a permutation testing to examine how much information I have to against the null hypothesis that the treatment effect does not exist. I plan to randomly shuffle the country labels. In the permutation test, I deliberately destroy the relationship between political reforms and trade policy reforms and produce a null distribution. What I expect from this process of statistical inference is to approximate the process of repeating an hypothetical experiment on population -- the developing countries. I also know that my hypothetical experiment pool is fairly large (N=179), so the Central Limit Theorems can help me to get a hypothesized null reference distribution without actually repeating the experiment. In my dataset, I also worry about the assumption of IID because I suspect the random variables are not independent and identically distributed. In this section, I will use a simple univariate regression model to demonstrate the process of using a variety of ways to get a robust standard error for my model.  



There is an a priori reason to suspect that there is heteroscedasticity in my data, given that this problem is common in time-series cross-sectional data. Heteroscedasticity occurs when the variance of the errors varies across observations (Long & Ervin, 2000, p.217). In simple words, when the variance of errors is not constant, one of the important assumptions of a linear model, homoscedasticity is violated. In the presence of heteroscedasticity, ordinary least squares estimates are still consistent, but the tests of significance are generally inappropriate because the standard errors obtained from the classic variance covariance matrix are no longer consistent. We will then perform an invalid statistical inference if we do not correct for the possible presence of heteroskedasticity. Figure 2 reveals that we might have a heteroskedasticity problem.



I simplify my regression without controlling for covariates as the following at this moment:
$tradepolicy_{i,t} = \beta_0 + \beta_1*REGIME_{i,t-1} + \varepsilon_i$. I calculated the HC0, HC1, HC2, and HC3 robust standard errors by covariate matrix, by using a "sandwich" R-statistic package and by "wild bootstrap" simulation to cross-check. The "HC" standard errors taking into account the Heteroscedasticity and the by-default standard errors are in fact very close. The "Robust Cluster" standard errors, however, are quite different from those two. I will continue to work on this part.  


```{r create covariates matrix, eval=T, echo=F, results="hide"} 

#OLS_3_5_0 <- lm(Tariff ~ Regime_l1 + log(GDP_l1) + EC_l1 + WTO_l1, data=mydata3, na.action = na.exclude)
#Regime_l1_Bi_s <- mydata4_small$Regime_l1_Bi
#GDP_l1_s <- mydata4_small$`GDP PC 95(t-1)`
#EC_l1_s <- mydata4_small$`Economic Crisis(t-1)`
#WTO_l1_s <- mydata4_small$`GATT/WTO(t-1)`
Regime_l1_m4 <- mydata4_small$`Regime(t-1)`
OLS_4_0 <- lm(Tariff~Regime_l1_m4, data=mydata4_small)
summary(OLS_4_0)

#X <- model.matrix(~Regime_l1, data=mydata4_small)#use the discrete polity score
#nrow(X) #3246 observations

X_m4 <- model.matrix(~Regime_l1_m4) #make a model matrix
dim(X_m4) #662

y_m4<- mydata4_small$Tariff
N <- length(y_m4) #662 observations

b_m4<- solve(t(X_m4) %*% X_m4) %*% t(X_m4) %*% y_m4 #coefficient Regime: NA because there are missing values in y
b_m4 #-0.3862

ehat_m4<-y_m4 - (X_m4 %*% b_m4)
names(ehat_m4)<-row.names(mydata4_small)
sigma2_m4<-sum(ehat_m4^2)/(nrow(mydata4_small)-length(b_m4)) 
#sum(ehat^2) is the sum of residuals sqaures; sigam^2 is the variance of the random errors, which equals to sample variance of the residuals/degree of freedom.

vcovb_m4<- sigma2_m4 * solve(t(X_m4) %*% X_m4) 
vcovb_m4
#This is covariance matrix for the estimated coefficients. 

seb_m4<-sqrt(diag(vcovb_m4))
seb_m4
#This is the standard errors for estimated coefficients.

cbind(b_m4,seb_m4)
#This is the matrix of coefficients and standard errors

```

```{r formal test, eval=T, echo=F, results="hide", warning=F} 

#Performs the (formal) Breusch-Pagan test against heteroskedasticity.
bptest(Tariff~Regime_l1_m4, data=mydata4_small)
#The Breusch-Pagan test fits a linear regression model to the residuals of a linear regression model. 
#The residuals should not be well explained by the predictors. My null hypothesis here is variance of error is constant. 
#The p-value is 1, which means that we do not reject against the null hypothesis of homoscedasticity. There is possibly not a problem of heteroskedasticity in the dataset.
```

```{r, eval=T, echo=F, results="hide", warning=F} 

OLS_4_0 <- lm(Tariff~Regime_l1_m4, data=mydata4_small)
summary(OLS_4_0)

library(ggplot2)

ggplot(data=NULL, aes(OLS_4_0$fitted.values, OLS_4_0$residuals^2))+
  geom_point()+
  geom_hline(yintercept = 0)+
  theme_classic()+
  xlab("fitted values")+
  ylab("squared residuals")

```


```{r produce HC0, HC1, HC2, HC3, eval=T, echo=F, results="hide", warning=F} 

OLS_4_0 <- lm(Tariff~Regime_l1_m4, data=mydata4_small)
summary(OLS_4_0)

#We use Long & Ervin (2000) and the code, along with the sandwich package to calculate HC0... etc. 
H_m4 <- diag(X_m4 %*% solve(t(X_m4) %*% X_m4) %*% t(X_m4)) #This is leverage, Leverage tells us how much pull a particular value of Xi exerts on the regression line (Angrist & Pischke).

#install.packages("sandwich")
library(sandwich)

##OLS standard Errors
## We need an N x N matrix in the middle of this next calculation
vcovIID_m4 <- (solve(crossprod(X_m4)) %*% t(X_m4)) %*% (sigma2_m4 * diag(1,N,N))%*% (X_m4%*%solve(crossprod(X_m4)))
#vcov(OLS_4_0) by default function
sebIID_m4  <- sqrt(diag(vcovIID_m4))

sebIID_m4 #this is the same as the coeff from the canned regression under the assumption of homoscedasticity

sandseb_m4<- sqrt(diag(vcovHC(OLS_4_0, type = "const")))
sandseb_m4 #sebIID_m4 == sandseb_m4


## Make a block diagonal sigma/middle matrix
thesigmaHC0_m4<-diag(as.vector(ehat_m4)^2,nrow=length(ehat_m4),ncol=length(ehat_m4))
dimnames(thesigmaHC0_m4)<-list(names(ehat_m4),names(ehat_m4))

##HC0
vcovHC0_m4 <- (solve(crossprod(X_m4)) %*% t(X_m4)) %*% (thesigmaHC0_m4) %*% ( X_m4 %*% solve(crossprod(X_m4)))

sebHC0_m4<-sqrt(diag(vcovHC0_m4))
sandsebHC0_m4 <- sqrt(diag(vcovHC(OLS_4_0, type = "HC0")))

sebHC0_m4
sandsebHC0_m4

##HC1
vcovHC1_m4 <- (N/(N-2))*vcovHC0_m4 ## 2 coeff: beta1, intercept

sebHC1_m4 <-sqrt(diag(vcovHC1_m4))
sandsebHC1_m4 <- sqrt(diag(vcovHC(OLS_4_0, type = "HC1")))

sebHC1_m4
sandsebHC1_m4

##HC2
thesigmaHC2_m4<-diag(as.vector(ehat_m4)^2/(1-H_m4),nrow=length(ehat_m4),ncol=length(ehat_m4))
dimnames(thesigmaHC2_m4)<-list(names(ehat_m4),names(ehat_m4))

vcovHC2_m4 <- (solve(crossprod(X_m4)) %*% t(X_m4)) %*% (thesigmaHC2_m4) %*% ( X_m4 %*% solve(crossprod(X_m4)))
##car::hccm(OLS_4_0,type="hc2")

sebHC2_m4 <- sqrt(diag(vcovHC2_m4))
sandsebHC2_m4 <- sqrt(diag(vcovHC(OLS_4_0, type = "HC2")))

sebHC2_m4
sandsebHC2_m4

#HC3 Long & Ervin prefer HC3 write that HC3 divides ehat^2 by (1-h)^2 further inflates ehat^2 which adjusts for the over influence of observations with large variances (this may be most suitable for my cases)
thesigmaHC3_m4<-diag(as.vector(ehat_m4)^2/(1-H_m4)^2,nrow=length(ehat_m4),ncol=length(ehat_m4))
dimnames(thesigmaHC3_m4)<-list(names(ehat_m4),names(ehat_m4))

vcovHC3_m4 <- (solve(crossprod(X_m4)) %*% t(X_m4)) %*% (thesigmaHC3_m4) %*% ( X_m4 %*% solve(crossprod(X_m4)))

#car::hccm(OLS_4_0,type="hc3")
#These are also called ??White-corrected?? or ??White-Huber?? covariance matrices.

sebHC3_m4 <- sqrt(diag(vcovHC3_m4))
sandsebHC3_m4 <- sqrt(diag(vcovHC(OLS_4_0, type = "HC3")))

sebHC3_m4
sandsebHC3_m4

```


```{r, eval=T, echo=F, results="hide", warning=F} 
#options(digits=4)
#Without considering clustering
SEhc0_m4 <- sqrt(car::hccm(OLS_4_0,type="hc0")[2,2])
SEhc1_m4 <- sqrt(car::hccm(OLS_4_0,type="hc1")[2,2])
SEhc2_m4 <- sqrt(car::hccm(OLS_4_0,type="hc2")[2,2])
SEhc3_m4 <- sqrt(car::hccm(OLS_4_0,type="hc3")[2,2])

SEhc0_m4
SEhc1_m4
SEhc2_m4
SEhc3_m4


library(multiwayvcov)

#Consider clustering
## For comparison, produce White HC0 VCOV the hard way
vcov_hc0_cm4 <- cluster.vcov(OLS_4_0, 1:nrow(mydata4_small), df_correction = FALSE)
coeftest(OLS_4_0, vcov_hc0_cm4)
## Produce White HC1 VCOV the hard way
vcov_hc1_cm4 <- cluster.vcov(OLS_4_0, 1:nrow(mydata4_small), df_correction = TRUE)
coeftest(OLS_4_0, vcov_hc1_cm4)
## Produce White HC2 VCOV the hard way
vcov_hc2_cm4 <- cluster.vcov(OLS_4_0, 1:nrow(mydata4_small), df_correction = FALSE, leverage = 2)
coeftest(OLS_4_0, vcov_hc2_cm4)
## Produce White HC3 VCOV the hard way
vcov_hc3_cm4 <- cluster.vcov(OLS_4_0, 1:nrow(mydata4_small), df_correction = FALSE, leverage = 3)
coeftest(OLS_4_0, vcov_hc3_cm4)

```

```{r, eval=T, echo=F, results="hide", warning=F} 


##Comments: there are not many differences between clustered and non-clustered HC0, HC1, HC2, and HC3.

##Consider clustering with cluster.cov
# Cluster by country
vcov_cm4_c <- cluster.vcov(OLS_4_0, mydata4_small$Country)
coeftest(OLS_4_0, vcov_cm4_c)
# Cluster by year
vcov_cm4_y <- cluster.vcov(OLS_4_0, mydata4_small$Year)
coeftest(OLS_4_0, vcov_cm4_y)

##Comments: Here, if we use double clusters, there are differences.

# Double cluster by country and year (default: computing White(1980) variance-covariance matrices)
cov_dcm4 <- cluster.vcov(OLS_4_0, cbind(mydata4_small$Country, mydata4_small$Year))
coeftest(OLS_4_0, cov_dcm4)

##Replicate Mahmood Arai's double cluster by country and year
cov_dcm4_MA <- cluster.vcov(OLS_4_0, cbind(mydata4_small$Country, mydata4_small$Year), use_white = F)
coeftest(OLS_4_0, cov_dcm4_MA)

```


```{r, eval=T, echo=F, results="hide", warning=F} 
# Wild Bootstrap. 
#https://cran.r-project.org/web/packages/multiwayvcov/multiwayvcov.pdf


set.seed(19900814)
#install.packages("multiwayvcov")
library(multiwayvcov)
library(lmtest)
OLS_4_0 <- lm(Tariff~Regime_l1_m4, data=mydata4_small)

# Wild Bootstrap
vcovWB_m4 <- cluster.boot(OLS_4_0,cluster=1:nrow(mydata4_small),boot_type="wild")
coeftest(OLS_4_0,vcovWB_m4)

# Clustered Wild Bootstrap
##Cluster by country
vcovWBC_m4_c <- cluster.boot(OLS_4_0,cluster=mydata4_small$Country,boot_type="wild")
coeftest(OLS_4_0,vcovWBC_m4_c) # Wild Bootstrap with Clustering by country

#Cluster by year
vcovWBC_m4_y <- cluster.boot(OLS_4_0,cluster=mydata4_small$Year,boot_type="wild")
coeftest(OLS_4_0,vcovWBC_m4_y) # Wild Bootstrap with Clustering by year

# Double cluster by country and year
vcovWBC_m4_cy <- cluster.boot(OLS_4_0, cluster=cbind(mydata4_small$Country, mydata4_small$Year),boot_type = "wild")
coeftest(OLS_4_0, vcovWBC_m4_cy)

```
The robust standard errors and clustered robust standard errors are reported as the following:  


|Standard Errors|Number  |
|--------|----------------:|
|OLS standard error|0.0834|
|Robust HCO|0.0802|
|Robust HC1|0.0803|
|Robust HC2|0.0803|
|Robust HC3|0.0804|
|Wild Bootstrap|0.0843|
|Clustered Robust SEs by Country in Covariate Marix|0.16|
|Clustered Robust SEs by Year in Covariate Marix|0.105|
|Clustered Robust SEs by Double Clusters (Country and Year) in Covariate Marix|0.173|
|Clustered Wild Bootstrap SEs by Country| 0.173|
|Clustered Wild Bootstrap SEs by Year|0.10|
|Clustered Wild Bootstrap SEs by Double Clusters|0.175|



```{r, eval=T, echo=F, results="hide", warning=F} 
#In a non-bootstrap world (to compute Wald confidence intervals)
#https://www.rdocumentation.org/packages/lmtest/versions/0.9-36/topics/coeftest

coefci(OLS_4_0, parm = NULL, level = 0.95, vcov. = vcov_cm4_c, 
       df = (nrow(mydata4_small)-length(b_m4))) #CI for clustering by country

coefci(OLS_4_0, parm = NULL, level = 0.95, vcov. = vcov_cm4_y, 
       df = (nrow(mydata4_small)-length(b_m4))) #CI for clustering by year

coefci(OLS_4_0, parm = NULL, level = 0.95, vcov. = cov_dcm4, 
       df = (nrow(mydata4_small)-length(b_m4))) #CI for double clustering by country and year (white)

coefci(OLS_4_0, parm = NULL, level = 0.95, vcov. = cov_dcm4_MA, 
       df = (nrow(mydata4_small)-length(b_m4))) #CI for double clustering by country and year (MA)

```

```{r, eval=T, echo=F, results="hide", warning=F} 

##Apply to other functions
OLS_4_1 <- lm(Tariff~Regime_l1_m4 + mydata4_small$`GDP PC 95(t-1)`, data=mydata4_small)
summary(OLS_4_1)

cov_dcm4_1_MA <- cluster.vcov(OLS_4_1, cbind(mydata4_small$Country, mydata4_small$Year), use_white = F)
coeftest(OLS_4_1, cov_dcm4_1_MA)

```


Note that I will continue to work on this part in the final project.  


#Section III: In the presence of Hetereogeneity: Matching and OLS


Recall, a critical challenge in the observational data is to make the comparison of apples to apples, oranges to oranges. The idea of "controlling for" or statistical adjustment is to get rid of the selection bias or omitted variables bias in the causal inference route (Angrist & Pischke, 2015). Random assignment can solve this potential problem and facilitate causal inference because before the experiment, the potential outcomes are independent of the treatment the subjects receive. The critical point is the attributes of the subjects are not related to whether they will receive the treatment (Shadish et al., 2002). In the observational studies, the path to random assignment is blocked. we rely heavily on the assumption of ignorability of the treatment assignment. We hope that although no actual randomized assignment takes place, units randomly assigned to the treatment effects after we control for the confounding covariates (Gelman and Hill, 2007). In other words, we hope that adding control of the covariates or controlling for country- or time-specific factors (fixed effects model) can help us achieve the goal that treatment can be independent of potential outcomes. Matching (an as-if random design) can help us one step further to ensure we balance the pre-treatment effects to make the right comparison. This is the next step of this paper. 


Panel data suggests that individuals, firms, states or countries are heterogeneous. In other words, there are pretreatment bias in the data generating process. If we use time-series and cross-section data without considering the potential of heterogeneity, we may run the risks of obtaining biased results (Baltagi, 2005, p. 4). This paper uses a panel of 179 developing countries observational data over the period from 1980 through 99. These countries differ in terms of their financial insitutions, economic development stages, political regimes, membership of the international organizations, and many other wagys. All of these country-specific factors affect the tariff rates they adopt. Some unobservable country-specific effects may bias the estimates. In the time-series data, there is also potentially observed and unobserved heterogeneity of some omitted variables that are systematically correlated with the dependent variable. One of the threats to internal validity in the research design is maturation: the processes or trends within the dependent variables and the independent variables produce changes as a function of time, per se (Campbell, 1969, p. 411). In this case, regimes may tend to be more democratized politically and liberalized economically over time. The fixed-effect models allow us to control for variables that change over time within each country. Not accounting for the country and year heterogeneity may cause serious misspecification. 


In a panel data regression, I attempt to account for unobservable country-specific effects in the model:  


$tradepolicy_{i,t} = \beta_0 + \beta_1*REGIME_{i,t} + \beta_2*GDPPC_{i,t} + \beta_3*ECCRISIS_{i,t} + \beta_4*WTO_{i,t} + \beta_5*OFFICE_{i,t} + \mu_{it} + \varepsilon_i$  


, with *i* denoting countries and *t* denoting time. We can use a one-way error component model for the disturbances, with $\mu_{it} = u_i + v_it$ where $u_i$ denotes the unobservable country-specific effect and $v_it$ denotes the remainder disturbances. In this case, the $u_i$ are assumed to be fixed parameters to be estimated and the remainder disturbances vit are independent and identically distributed (iid) (Baltagi, 2005, p. 12).  

```{r, eval=T, echo=F, results="hide", warning=F,include=F} 

#Find Heterogeneity across countries

#Selected countries, n=5
#plotmeans(Tariff ~ Country, main="Heterogeineity across countries", data = mydata4_small)
#plotmeans(Tariff ~ Year, main="Heterogeineity across countries", data = mydata4_small)


#All the countries: how to interpret the graph?

plotmeans(Tariff ~ Country, main="Heterogeineity across countries", data = mydata4_small)
#plotmeans draw a 95% confidence interval around the means
#Heterogeneity: unobserved variables that do not change over time 

#All the years
plotmeans(Tariff ~ Year, main="Heterogeineity across years", data = mydata4_small)
```


```{r, eval=T, echo=F, results="hide", warning=F,include=F} 

#install.packages("plm")
library(plm)
##Try fixed effects using least squares dummy variable model (LSDV model)
fixed.dum <- lm (Tariff ~ Regime_l1_m4 + factor(Country) - 1, data=mydata4_small)
summary(fixed.dum)
#In the LSDV model, each component of the factor variable (country) is absorbing the effects particular to each country. 
#The coefficient of x1 indicates how much Y changes overtime, controlling by differences in countries, when X increases by one unit.

##fixed effexts: n entity-specific intercepts
fixed.plm <- plm(Tariff ~ Regime_l1_m4, data=mydata4_small, index=c("Country", "Year"), model="within")
summary(fixed.plm)
#the note (unbalanced panel) refers to the fact that some ctounries do not have data for one or some years. Ideally you would want to balanced dataset but this is not always the case, however you can still run the model. 
#However, the p-value is big, sugesting that we cannot reject that all the coeeficients in the model are different than zero.
#The coeff of x1 indicates how much Y changes overtime, on average per country, when X increases by one unit.

pFtest(fixed.plm, OLS_4_0) #the fixed effect model is a better choice compared to the OLS model.

##random effects:
random <- plm(Tariff ~ Regime_l1_m4, data=mydata4_small, index=c("Country", "Year"), model="random")
summary(random)

#In the case of TSCS data represents the average effect of X over Y when X changes across time and between countries by one unit.

phtest(fixed.plm, random) #p is larger than 0.05; random effects are better than fixed effects.

##Testing for time-fixed effects
fixed.time <- plm(Tariff ~ Regime_l1_m4 + factor(Year), data=mydata4_small, index=c("Country", "Year"), model="within")
summary(fixed.time)

##Testing time-fixed effects. The null is that no time-fixed effects needed.
plmtest(fixed.plm, c("time"), type=("bp"))
pFtest(fixed.time, fixed.plm)
#P is very low; then it is better to use time-fixed effects.

##Testing cross-sectional depedence correlation:

```


```{r, results='asis', echo=FALSE}
cat("\\newpage")
```

```{r appendix, ref.label=knitr::all_labels(),echo=TRUE,eval=FALSE}

```

#Citation

Achen, Christopher H. 1982. Interpreting and Using Regression. Newbury Park, CA: Sage.


Angrist J., Pischke J-S. 2015. Mastering 'Matrics: The Path from Cause to Effect


Baccini, L., & Urpelainen, J. (2014). International Institutions and Domestic Politics: Can Preferential Trading Agreements Help Leaders Promote Economic Reform? The Journal of Politics, 76(1), 195-214. https://doi.org/10.1017/S0022381613001278

Campbell. "Reforms as Experiments," American Psychologist, 1969, pp. 409-429.

Gelman, A., and J. Hill. 2007. Data Analysis Using Regression and Multilevel/
Hierarchical Models. Cambridge University Press.


Kruger, Anne. 1997. Trade Policy and Economic Development: How We Learn. American Economic Review 87(1): 1-22.


Mansfield E.D, Eric Reinhardt. 2003. "Multilateral Determinants of Regionalism: The Effects of GATT/WTO on the Formation of Preferential Trading Arrangements," International Organization 57:4, 829-862.

Mansfield, E. D., Milner, H. V., & Rosendorff, B. P. (2002). Why Democracies Cooperate More: Electoral Control and International Trade Agreements. International Organization, 56(3), 477-513.

Rodrik, Dani. 1994. "The Rush to Free Trade in Developing World: Why So Late? WHy Now? Will it Last?" In Voting for Reform, edited by Stephan Saggard and Steven Webb, 1457-94. New York: Oxford University Press.

Shadish W., Cook T. and Campbell, Eperimental and Quasi-Experimental Designs. 2002.


Vreeland, James Raymond. 2007. The International Monetary
Fund: Politics of Conditional Lending. New York:
Routledge